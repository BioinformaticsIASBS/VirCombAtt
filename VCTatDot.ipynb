{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f358e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MultiheadAttention, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b838d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugVirusDataset(Dataset):\n",
    "    def __init__(self, drug1_sim, drug1_tensor, drug2_sim, drug2_tensor, virus_tensor, label):\n",
    "\n",
    "        self.drug1_tensor = drug1_tensor\n",
    "        self.drug1_sim = drug1_sim\n",
    "        self.drug2_tensor = drug2_tensor\n",
    "        self.drug2_sim = drug2_sim\n",
    "        self.virus_tensor = virus_tensor\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.drug1_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        drug1 = self.drug1_tensor[idx]\n",
    "        drug1_sim = self.drug1_sim[idx]\n",
    "        drug2 = self.drug2_tensor[idx]\n",
    "        drug2_sim = self.drug2_sim[idx]\n",
    "        virus = self.virus_tensor[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        return drug1, drug1_sim, drug2, drug2_sim, virus, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scientific_notation(value):\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d447c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_combinations_index_file(file_path):\n",
    "    combinations = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            temp_line = line.strip().split()\n",
    "            indices = []\n",
    "            for i in range(len(temp_line)):\n",
    "                indices.append(parse_scientific_notation(temp_line[i]))\n",
    "            combinations.append(indices)\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = read_combinations_index_file('Data/XIndex_ratio100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [parse_scientific_notation(line.strip()) for line in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab47697",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_path = 'Data/Y_ratio100.txt'\n",
    "labels_list = read_label_file(label_file_path)\n",
    "label_tensor = torch.tensor(labels_list,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48882ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_df = pd.read_excel('Data/small_mulecule_drug_similarity.xlsx')\n",
    "drugs = drugs_df['smiles']\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in drugs_df['smiles']]\n",
    "rdkit_gen = rdFingerprintGenerator.GetRDKitFPGenerator(maxPath=7)\n",
    "fps = [rdkit_gen.GetFingerprint(mol) for mol in mols]\n",
    "smile_tensor = torch.tensor(fps,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "viruses_df = np.loadtxt('Data/Similarity_Matrix_Viruses.txt')\n",
    "viruses = torch.tensor(viruses_df, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_sim_df = np.loadtxt('Data/Similarity_Matrix_Drugs.txt')\n",
    "drugs_sim = torch.tensor(drugs_sim_df, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd820429",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1_tensor = torch.randn(len(combinations),2048)\n",
    "drug1_sim_tensor = torch.randn(len(combinations),211)\n",
    "drug2_tensor = torch.randn(len(combinations),2048)\n",
    "drug2_sim_tensor = torch.randn(len(combinations),211)\n",
    "virus_tensor = torch.randn(len(combinations),44)\n",
    "for i in range(len(combinations)):\n",
    "    drug1_tensor[i] = smile_tensor[combinations[i][0]]\n",
    "    drug1_sim_tensor[i] = drugs_sim[combinations[i][0]]\n",
    "    drug2_tensor[i] = smile_tensor[combinations[i][1]]\n",
    "    drug2_sim_tensor[i] = drugs_sim[combinations[i][1]]\n",
    "    virus_tensor[i] = viruses[combinations[i][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4763ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrugVirusDataset(drug1_sim_tensor, drug1_tensor, drug2_sim_tensor, drug2_tensor, virus_tensor, label_tensor)\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "\n",
    "train_indices, temp_indices, train_labels, temp_labels = train_test_split(indices, label_tensor, test_size=0.2, stratify=label_tensor, random_state=42)\n",
    "\n",
    "test_indices, val_indices, _, _ = train_test_split(temp_indices, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "\n",
    "\n",
    "train_set = Subset(dataset, train_indices)\n",
    "test_set = Subset(dataset, test_indices)\n",
    "val_set = Subset(dataset, val_indices)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33eb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(nn.Module):\n",
    "    def __init__(self,input_dim, embedding_dim, num_heads):\n",
    "        super(Self_Attention, self).__init__()\n",
    "        self.projection = nn.Linear(input_dim, embedding_dim)\n",
    "        self.self_attention = MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads,  batch_first =True, dropout = 0.2)\n",
    "        self.layerNorm = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        proj = self.projection(x).unsqueeze(1)\n",
    "\n",
    "        attn_output, _ = self.self_attention(proj, proj, proj)\n",
    "        output = self.layerNorm(attn_output+proj)\n",
    "        return output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Attention(nn.Module):\n",
    "    def __init__(self,query_dim,key_dim, embed_dim, num_heads):\n",
    "        super(Cross_Attention, self).__init__()\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first =True, dropout = 0.2 )\n",
    "        self.embed_dim = embed_dim\n",
    "        self.query_projection = nn.Linear(query_dim, embed_dim)\n",
    "        self.key_projection = nn.Linear(key_dim, embed_dim)\n",
    "        self.layerNorm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        \n",
    "        query_proj = self.query_projection(query).unsqueeze(1) \n",
    "        key_proj = self.key_projection(key).unsqueeze(1)  \n",
    "\n",
    "        \n",
    "        attn_output, _ = self.cross_attn(query_proj, key_proj, key_proj)\n",
    "        output = self.layerNorm(attn_output+query_proj)\n",
    "\n",
    "        return output.squeeze(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attentionCancat(nn.Module):\n",
    "    def __init__(self,embeddding_dim, drug1_dim: int, drug2_dim: int, virus_sim_dim: int, drug_sim_dim: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.v = Self_Attention(virus_sim_dim, embeddding_dim, num_heads)\n",
    "        self.d1d2 = Cross_Attention(drug_sim_dim, drug_sim_dim, embeddding_dim, num_heads)\n",
    "        self.d2d1 = Cross_Attention(drug_sim_dim, drug_sim_dim, embeddding_dim, num_heads)\n",
    "    \n",
    "    def forward(self, drug1, drug2, virus):\n",
    "        v = self.v(virus)\n",
    "        d1d2 = self.d1d2(drug1,drug2)\n",
    "        d2d1 = self.d2d1(drug2,drug1)\n",
    "        x = [v,d1d2,d2d1]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c501ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificatioLayer(nn.Module):\n",
    "    def __init__(self, drug1_dim: int, drug2_dim: int, virus_sim_dim: int, drug_sim_dim: int, embedding_dim: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        self.att_cat = attentionCancat(embedding_dim, drug1_dim, drug2_dim, virus_sim_dim, drug_sim_dim, num_heads)\n",
    "\n",
    "        \n",
    "    def forward(self, d1, d2, v, d1_sim, d2_sim):\n",
    "        attn_cat = self.att_cat(d1_sim, d2_sim, v)\n",
    "        # Calculate dot product for classification\n",
    "        dot_product = torch.sum(attn_cat[0] * attn_cat[1] *  attn_cat[2], dim=-1)\n",
    "\n",
    "        output = dot_product.squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, predictions, prediction_scores):\n",
    "    set_of_labels = set(ground_truth)\n",
    "    assert False not in [label in set_of_labels for label in predictions],\\\n",
    "           'Predicted labels must be valid'      \n",
    "    accuracy = metrics.accuracy_score(ground_truth, predictions)\n",
    "    precision = metrics.precision_score(ground_truth, predictions)\n",
    "    recall = metrics.recall_score(ground_truth, predictions)\n",
    "    f1_score = metrics.f1_score(ground_truth, predictions)\n",
    "    MCC = metrics.matthews_corrcoef(ground_truth, predictions)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(ground_truth, predictions).ravel()\n",
    "\n",
    "    # Calculate specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    AUROC = metrics.roc_auc_score(ground_truth, prediction_scores)\n",
    "    AUPR = metrics.average_precision_score(ground_truth, prediction_scores)\n",
    "\n",
    "    return [accuracy, precision, recall, specificity, f1_score, MCC, AUROC, AUPR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ClassificatioLayer(2048, 2048, 44, 211, 1024 ,4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b08179",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_losses = []\n",
    "best_aupr = 0\n",
    "best_model_path = 'best_model.pth'\n",
    "for epoch in range(num_epochs):\n",
    "    #print('-'*100)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for d1, d1_sim ,d2, d2_sim,v, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(d1.to(device),d2.to(device),v.to(device), d1_sim.to(device), d2_sim.to(device))\n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "         for d1, d1_sim ,d2, d2_sim,v, labels in val_loader:\n",
    "            outputs = model(d1.to(device),d2.to(device),v.to(device), d1_sim.to(device), d2_sim.to(device))\n",
    "            predicted = (outputs.view(-1) > 0.5).float()\n",
    "            probs = (outputs.view(-1)).float()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "    # Compute evaluation metrics\n",
    "    evaluation_metrics = evaluate(y_true, y_pred, y_prob)\n",
    "    accuracy = evaluation_metrics[0]\n",
    "    precision = evaluation_metrics[1]\n",
    "    recall = evaluation_metrics[2]\n",
    "    specificity = evaluation_metrics[3]\n",
    "    f1_score = evaluation_metrics[4]\n",
    "    MCC = evaluation_metrics[5]\n",
    "    AUROC = evaluation_metrics[6]\n",
    "    AUPR = evaluation_metrics[7]\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'specificity: {specificity:.4f}')\n",
    "    print(f'F1 Score: {f1_score:.4f}')\n",
    "    print(f'MCC: {MCC:.4f}')\n",
    "    print(f'AUROC: {AUROC:.4f}')\n",
    "    print(f'AUPR: {AUPR:.4f}')\n",
    "    if (AUPR > best_aupr):\n",
    "        best_aupr = AUPR\n",
    "        print(epoch, AUPR)\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "    \n",
    "    # # Plot the training loss\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Load the best model for testing\n",
    "best_model = ClassificatioLayer(2048, 2048, 44, 211, 1024 ,4).to(device)\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "     for d1, d1_sim ,d2, d2_sim,v, labels in test_loader:\n",
    "        labels.to(device)\n",
    "\n",
    "        outputs = best_model(d1.to(device),d2.to(device),v.to(device), d1_sim.to(device), d2_sim.to(device))\n",
    "\n",
    "        predicted = (outputs.view(-1) > 0.5).float()\n",
    "        probs = (outputs.view(-1)).float()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_prob.extend(probs.cpu().numpy())\n",
    "\n",
    "# Compute evaluation metrics\n",
    "evaluation_metrics = evaluate(y_true, y_pred, y_prob)\n",
    "accuracy = evaluation_metrics[0]\n",
    "precision = evaluation_metrics[1]\n",
    "recall = evaluation_metrics[2]\n",
    "specificity = evaluation_metrics[3]\n",
    "f1_score = evaluation_metrics[4]\n",
    "MCC = evaluation_metrics[5]\n",
    "AUROC = evaluation_metrics[6]\n",
    "AUPR = evaluation_metrics[7]\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'specificity: {specificity:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n",
    "print(f'MCC: {MCC:.4f}')\n",
    "print(f'AUROC: {AUROC:.4f}')\n",
    "print(f'AUPR: {AUPR:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
